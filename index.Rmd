---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Seungho Lee; SL46699

### Introduction 

Paragraph or two introducing your datasets and variables, why they are interesting to you, etc. See instructions for more information

*Continuing with the theme from my project 1, I have decided to utilize the same nbastats dataset that was obtained from kaggle for my project. However, for the purpose of this project, this list of players have been narrowed down to the best 50 players (50 observations) from the 2018-2019 NBA season. Additionally, a new variable was added called "citizenship" which will be the binary variable for the dataset, and the I have also altered the stat variables from the original dataset in order to only work with the stats/variables that I was particularly interested in. The nbastats dataset includes character variables such as name, height, weight, team, and citizenship. The dataset also involves variables that measure numerical values such as age, salary, points, blocks, steals, assists, rebounds, free throw percentage, 3 point field goal percentage, field goal percentage, minutes played, and games played. For my binary variable ("citizenship"), there are 35 observations for USA and there are 15 observations for International. Also, the data did not need any tidying. I chose this particular dataset and these specific variables because growing up, basketball has always been a huge part of life. I loved playing basketball as well as watching NBA basketball. Whether I am on the court myself playing or watching my favorite player playing on TV, I was always engaged and interested in keeping up with the different statistics involved in the game of basketball.*
```{R}
library(tidyverse)
# read your datasets in here, e.g., with read_csv()
nbastats2018_2019 <- read_csv("nbastats2018-2019.csv", 
     col_types = cols(Height = col_number(), 
         Weight = col_number(), Age = col_number(), 
         Salary = col_number(), Points = col_number(), 
         Blocks = col_number(), Steals = col_number(), 
         Assists = col_number(), Rebounds = col_number(), 
         `FT%` = col_number(), `FG3%` = col_number(), 
         `FG%` = col_number(), MP = col_number(), 
         G = col_number()))
nbastats2018_2019
# if your dataset needs tidying, do so here

# any other code here

nbastats2018_2019 %>% filter(Citzenship == "USA")
nbastats2018_2019 %>% filter(Citzenship == "International")
```

### Cluster Analysis

```{R}
library(cluster)
# clustering code here
nbastats <-(na.omit(nbastats2018_2019))
subset(nbastats, select = -c(Name, Height, Weight, Team, Citzenship))
nbaclusterdata <- subset(nbastats, select = -c(Name, Height, Weight, Team, Citzenship))
sil_width <- vector()
for (i in 2:10) {
  kms <- kmeans(nbaclusterdata, centers = i)
  sil <- silhouette(kms$cluster, dist(nbaclusterdata))
  sil_width[i] <- mean(sil[, 3])
}
ggplot() + geom_line(aes(x = 1:10, y = sil_width)) + 
  scale_x_continuous(name = "k", breaks = 1:10)
nba_pam <- nbaclusterdata %>% pam(k = 2)
nba_pam
nba_pam$silinfo$avg.width
nbastats[23,]
nbastats[40,]
library(GGally)
nbaclusterdata %>% mutate(cluster = as.factor(nba_pam$clustering)) %>% 
    ggpairs(columns = c("Points", "Blocks", 
        "Steals", "Assists", "Rebounds", "Age", "cluster"), 
        aes(color = cluster))
nbaclusterdata %>% slice(nba_pam$id.med)
plot(nba_pam, which = 2)
```

Discussion of clustering here
*For this portion of the project, a new data called "nbastats" was created where it omitted all observations that included NAs. In the nbastats dataset, all the character columns such as Names, Teams, etc. were removed in order to move on with the PAM cluster analysis and this dataset was named "nbaclusterdata". The best number to use for a PAM clustering algorithm was k=2, and that was when the silhouette width was highest, at a value of around 0.67, which is the same as the overall average silhouette width. This number indicates that a reasonable structure has been found. Since all the names of the players were removed in the nba_pam data, I was not able to directly figure the names of the players directly. However, the user ID information was displayed from nba_pam and it was used in the "nbastats" data in order to find the names of the medoids. The two provinces that are the medoids were Jrue Holiday and Ben Simmons.*   
    
### Dimensionality Reduction with PCA

```{R}
# PCA code here
```

Discussions of PCA here. 

###  Linear Classifier

```{R}
# linear classifier code here
```

```{R}
# cross-validation of linear classifier here
```

Discussion here

### Non-Parametric Classifier

```{R}
library(caret)
# non-parametric classifier code here
```

```{R}
# cross-validation of np classifier here
```

Discussion


### Regression/Numeric Prediction

```{R}
# regression model code here
```

```{R}
# cross-validation of regression model here
```

Discussion

### Python 

```{R}
library(reticulate)
```

```{python}
# python code here
```

Discussion

### Concluding Remarks

Include concluding remarks here, if any




